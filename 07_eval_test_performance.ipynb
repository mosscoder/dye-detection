{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28923,"status":"ok","timestamp":1713210944117,"user":{"displayName":"Kyle Doherty","userId":"02054862309059506145"},"user_tz":420},"id":"8Sphhna4_t5n","outputId":"c2a156cd-a376-49e6-9136-7bb2a989f8f0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: jax 0.4.26\n","Uninstalling jax-0.4.26:\n","  Successfully uninstalled jax-0.4.26\n","Found existing installation: jaxlib 0.4.26+cuda12.cudnn89\n","Uninstalling jaxlib-0.4.26+cuda12.cudnn89:\n","  Successfully uninstalled jaxlib-0.4.26+cuda12.cudnn89\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\n","    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n","    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n","    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n","    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n","    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n","\n","    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n","Add token as git credential? (Y/n) Token is valid (permission: write).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n","\n"]}],"source":["!pip uninstall -y jax jaxlib\n","!pip install -Uqq datasets\n","\n","from google.colab import userdata, runtime\n","import subprocess\n","\n","hf_token = userdata.get('hf_token')\n","input_str = f'{hf_token}\\nn\\n'\n","result = subprocess.run(['huggingface-cli', 'login'], input=input_str, text=True, capture_output=True)\n","print(result.stdout)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11360,"status":"ok","timestamp":1713210955473,"user":{"displayName":"Kyle Doherty","userId":"02054862309059506145"},"user_tz":420},"id":"rqzzJD43_6zI","outputId":"0067d641-0792-4d61-eef1-b363d95050d8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","Number of available CPU cores: 2\n"]}],"source":["import os\n","import random\n","import numpy as np\n","import torch\n","from torch import nn\n","from torch.utils.data import DataLoader, default_collate\n","from torchvision.transforms import ToTensor, Compose, CenterCrop, Normalize\n","from sklearn.metrics import f1_score\n","import json\n","\n","from datasets import load_dataset\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Using device: {device}\")\n","\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","seed = 1984\n","\n","n_workers = os.cpu_count()\n","print(f'Number of available CPU cores: {n_workers}')"]},{"cell_type":"markdown","source":[],"metadata":{"id":"KAA5A-J0UW95"}},{"cell_type":"code","execution_count":7,"metadata":{"id":"AOr48XvlAg5g","executionInfo":{"status":"ok","timestamp":1713211244963,"user_tz":420,"elapsed":240,"user":{"displayName":"Kyle Doherty","userId":"02054862309059506145"}}},"outputs":[],"source":["results_dir = '/content/drive/MyDrive/Colab_Notebooks/dye_test_opt/ternary/results'\n","model_path = os.path.join(results_dir, 'models', 'test.pth')\n","\n","context_sz = 154 # 1x1 meter context\n","bs = 96\n","seed = 0\n","\n","imagenet_stats = {'mean': [0.485, 0.456, 0.406],\n","                  'std': [0.229, 0.224, 0.225]}"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3794,"status":"ok","timestamp":1713211405861,"user":{"displayName":"Kyle Doherty","userId":"02054862309059506145"},"user_tz":420},"id":"7hOlKlfmBHU7","outputId":"d00c1b1f-f259-455e-a4f2-83e078efc575"},"outputs":[{"output_type":"stream","name":"stdout","text":["Applying preprocessing transforms...\n"]}],"source":["ds = load_dataset('mpg-ranch/dye_test', split='test')\n","\n","# Preprocessing transforms\n","preprocs = Compose([\n","    CenterCrop((context_sz, context_sz)),\n","    ToTensor(),  # Convert the image to a PyTorch tensor\n","    Normalize(mean=imagenet_stats['mean'], std=imagenet_stats['std']),  # Normalize using ImageNet stats\n","])\n","\n","def preproc_transforms(examples):\n","    examples[\"img\"] = [preprocs(image.convert(\"RGB\")) for image in examples[\"image\"]]\n","    return examples\n","\n","print(\"Applying preprocessing transforms...\")\n","test_ds = ds.map(preproc_transforms, remove_columns=[\"image\",\"color\",\"size\",\"concentration\"], batched=True, batch_size=len(ds))\n","test_ds.set_format(type='torch')\n","n_classes = len(np.unique(test_ds['label']))"]},{"cell_type":"code","source":["def modified_f1_score(labels, predictions):\n","    scores = []\n","\n","    # For 1 vs. 0, exclude class 2 and consider only 1 and 0 for binary comparison\n","    mask_1_vs_0 = (labels != 2)\n","    labels_1_vs_0 = labels[mask_1_vs_0] == 1\n","    predictions_1_vs_0 = predictions[mask_1_vs_0] == 1\n","    if np.any(labels_1_vs_0) or np.any(predictions_1_vs_0):\n","        f1_1_vs_0 = f1_score(labels_1_vs_0, predictions_1_vs_0, pos_label=True, average='binary')\n","        scores.append(f1_1_vs_0)\n","\n","    # For 2 vs. 0, exclude class 1 and consider only 2 and 0 for binary comparison\n","    mask_2_vs_0 = (labels != 1)\n","    labels_2_vs_0 = labels[mask_2_vs_0] == 2\n","    predictions_2_vs_0 = predictions[mask_2_vs_0] == 2\n","    if np.any(labels_2_vs_0) or np.any(predictions_2_vs_0):\n","        f1_2_vs_0 = f1_score(labels_2_vs_0, predictions_2_vs_0, pos_label=True, average='binary')\n","        scores.append(f1_2_vs_0)\n","\n","    # Calculate the mean of the F1 scores if any valid scores were calculated\n","    mean_f1 = np.mean(scores) if scores else 0.0\n","\n","    return f1_1_vs_0, f1_2_vs_0, mean_f1"],"metadata":{"id":"_A3JeUIuRcxu","executionInfo":{"status":"ok","timestamp":1713211409975,"user_tz":420,"elapsed":360,"user":{"displayName":"Kyle Doherty","userId":"02054862309059506145"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10296,"status":"ok","timestamp":1713211420270,"user":{"displayName":"Kyle Doherty","userId":"02054862309059506145"},"user_tz":420},"id":"_WY7XtDRBL7w","outputId":"ed7c589f-edc8-4e15-d253-f8cc1206bb05"},"outputs":[{"output_type":"stream","name":"stdout","text":["Seed: 0\n","Loading model...\n"]},{"output_type":"stream","name":"stderr","text":["Using cache found in /root/.cache/torch/hub/facebookresearch_dinov2_main\n"]},{"output_type":"stream","name":"stdout","text":["Running inference...\n","Blue F1 score: 0.9222\n","Red F1 score: 0.9789\n","Mean F1 score: 0.9506\n"]}],"source":["print(f\"Seed: {seed}\")\n","random.seed(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)\n","\n","test_loader = DataLoader(test_ds, batch_size=bs, shuffle=False, num_workers=0)\n","\n","def load_model(arch, n_classes):\n","    print(\"Loading model...\")\n","    model = torch.hub.load('facebookresearch/dinov2', arch)\n","    num_ftrs = model.norm.normalized_shape[0]\n","    model.head = nn.Linear(num_ftrs, n_classes)\n","    model.to(device)\n","    return model\n","\n","model = load_model('dinov2_vitb14', n_classes)\n","state_dict = torch.load(model_path)\n","model.load_state_dict(state_dict)\n","\n","model.eval()\n","\n","print(\"Running inference...\")\n","\n","all_labels, all_predictions = [], []\n","with torch.no_grad():\n","    preds = []\n","    for data in test_loader:\n","        inputs, labels = data['img'].to(device), data['label'].to(device)\n","        outputs = model(inputs)\n","        _, predicted = torch.max(outputs.data, 1)\n","        all_labels.extend(labels.cpu().numpy())\n","        all_predictions.extend(predicted.cpu().numpy())\n","\n","    # Compute F1 score\n","    blue, red, f1 = modified_f1_score(np.array(all_labels), np.array(all_predictions))\n","    print(f\"Blue F1 score: {blue:.4f}\\nRed F1 score: {red:.4f}\\nMean F1 score: {f1:.4f}\")\n","\n","with open(os.path.join(results_dir, 'f1_test_results_overall.json'), 'w') as f:\n","    json.dump({'blue': blue, 'red': red, 'mean': f1}, f)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"Xv09pCY8CHR0","executionInfo":{"status":"ok","timestamp":1713211428192,"user_tz":420,"elapsed":245,"user":{"displayName":"Kyle Doherty","userId":"02054862309059506145"}}},"outputs":[],"source":["results_df = ds.to_pandas()\n","results_df['pred'] = all_predictions\n","results_df.drop(columns=['image'], inplace=True)\n","results_df.to_csv(os.path.join(results_dir, 'test_results.csv'), index=False)"]},{"cell_type":"code","source":["runtime.unassign()"],"metadata":{"id":"GC2x9LLeEm74"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"QvVPi5ZYU_YB"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"V100","provenance":[],"mount_file_id":"1DFxI2lXqvWGZyHUUEabxNlLPWiKBCXRK","authorship_tag":"ABX9TyNDmbMNmBKqxipKFNYFUFad"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}